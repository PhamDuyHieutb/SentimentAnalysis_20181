tập lệnh :
1.Run preprocessdata.py để xử lý data ban đầu
2.Vào libsvm và chạy lệnh:
tìm tham số c, slack bằng gói grid : python ./libsvm-3.22/tools/grid.py -log2c -5,15,2 -log2g 3,-15,-2 datatrainsvm  
3.Training bằng gói train: svm-train -c 32 -g 0.0078125 -t 2 datatrainsvm ./test/model
4.Tiến hành predict :svm-predict datatestsvm ./test/model ./test/result
trong đó datatrainsvm,datatestsvm là dữ liệu đã chuyển về dạng ma trận dày

5. Với đầu ra được predict ta chạy visualizeData.py để thể hiện kết quả lên bằng hình ảnh.	




optimization finished, #iter = 39962
nu = 0.193882
obj = -616634.838630, rho = 0.978030
nSV = 22314, nBSV = 19379
Total nSV = 22314
hieupd@hieupd:~/PycharmProjects/sentimentAnalysisSVM_20181/data/libsvm-3.22$ svm-predict datatestsvm ./test/model ./test/result
Accuracy = 88.1659% (46586/52839) (classification)


###############################
CHiến lược hiện tại:
- sẽ ưu tiên lấy review có vote, thiếu sẽ lấy thêm review k có vote
- xử lý negation theo phương pháp thông thường: ghép not vào từ tiếp theo ( chưa xử lý đc từ ghép 3)
- sửa lỗi chính tả với các từ viết sai nhưng có ý nghĩa với sentiment của câu/document
(làm trong 2h)



0.791011808682355
[[3171  671   78]
 [ 953 2538  458]
 [  72  228 3602]]


after use negation handling
0.7859628278027667
[[3214  719   57]
 [ 946 2504  476]
 [  66  258 3543]]

vấn đề :
+ còn sai ở việc gán nhãn 0 và 1 => lẫn nhau quá nhiều
=> lý do tại sao

+ mình muốn xây dựng một model phân loại có khả năng detected được sentiment trên nhiều domain => combine a large number of datasets


+ để biết đc vì sao sai ở negative và neutral
=> cần chia train test trước khi clean review => từ đó sẽ giữ được câu gốc để đối chiếu
=> cần gán negation word và number trước khi make dictionary và filter theo từ điển

* lần 3: xử lý thêm number star
0.7958992683341841
[[3249  671   70]
 [ 942 2495  417]
 [  43  256 3611]]

=> tiếp tục xử lý vấn đề tại sao sai sau khi có kết quả

* lần 4 sau khi xử lý number star => kết quả giảm 1% (có thể do dữ liệu nhiều hơn)

0.7857384938656544
[[3880  978  126]
 [1124 3157  565]
 [  79  289 4555]]


=> sai vị trí xét so sánh

* lần chạy thứ 5
average 0.8047857239421387
recall 0.8035723274801244
precision 0.8016934898613478
F1 0.8021091337771239
Confusion matrix, without normalization
[[3976  889  112]
 [1094 3303  437]
 [  70  286 4627]]


############### clothes $$$$$$$$$$$

0.7152375824471665   C = 32, g = 0.0078125


0.7118050881679903









